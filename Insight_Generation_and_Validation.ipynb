{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33686939-1590-44f6-a626-1954e833369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "GEMINI_API_KEY=\"AIzaSyBa0Ro237Wa8djCz8v5B24tVQoTk9zjrAE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd300419-fb33-494a-bca0-969d13a8c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\91901\\anaconda3\\lib\\site-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36eea18-0e00-46d0-b347-3c3afe3d97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = gemini_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13725dd9-84c0-4340-8c9d-4ef5a7caf23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete: Data and Prompt content defined.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = \"C:/Users/91901/Downloads/synthetic_fb_ads_undergarments.csv\" \n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}. Please check your path.\")\n",
    "    raise\n",
    "\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "\n",
    "daily_df = df.groupby('date').agg(\n",
    "    spend=('spend', 'sum'),\n",
    "    revenue=('revenue', 'sum'),\n",
    "    impressions=('impressions', 'sum'),\n",
    "    clicks=('clicks', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "daily_df['daily_roas'] = daily_df['revenue'] / daily_df['spend']\n",
    "daily_df['daily_ctr'] = (daily_df['clicks'] / daily_df['impressions']) * 100 \n",
    "\n",
    "\n",
    "latest_date = daily_df['date'].max()\n",
    "start_date_7d = latest_date - pd.Timedelta(days=6)\n",
    "last_7d_df = daily_df[daily_df['date'] >= start_date_7d].copy()\n",
    "\n",
    "data_agent_summary = {\n",
    "    'Timeframe_Start': start_date_7d.strftime('%Y-%m-%d'),\n",
    "    'Timeframe_End': latest_date.strftime('%Y-%m-%d'),\n",
    "    'Daily_Performance': last_7d_df[['date', 'daily_roas', 'daily_ctr', 'spend']].to_dict('records')\n",
    "}\n",
    "\n",
    "\n",
    "INSIGHT_PROMPT_CONTENT = \"\"\"\n",
    "# Insight Agent Prompt\n",
    "## ROLE\n",
    "You are an expert Facebook Performance Analyst. Your task is to diagnose the change in ROAS over the given timeframe and identify the most likely drivers.\n",
    "## DATA CONTEXT\n",
    "Daily Performance (ROAS is calculated as Revenue/Spend, CTR is in %):\n",
    "- Timeframe: {TIMEFRAME_START} to {TIMEFRAME_END}\n",
    "- User Query: {USER_QUERY}\n",
    "{DAILY_PERFORMANCE_DATA}\n",
    "## REASONING STRUCTURE (Think → Analyze → Conclude)\n",
    "1. Think: What is the most significant trend or anomaly in the daily ROAS/CTR/Spend data?\n",
    "2. Analyze: What 2-3 advertising issues could cause this trend?\n",
    "3. Conclude: Generate 2-3 specific hypotheses grounded strictly in the provided data.\n",
    "## OUTPUT FORMAT\n",
    "Provide the output as a clean, parsable JSON array (list) of objects.\n",
    "\"\"\"\n",
    "print(\"Setup Complete: Data and Prompt content defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf6c66d-6803-4864-83a9-407c604bea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Insight Agent Generated Hypotheses (Input for Evaluator) ---\n",
      "[\n",
      "    {\n",
      "        \"hypothesis_id\": \"H1\",\n",
      "        \"hypothesis\": \"The ROAS dropped primarily due to Audience Fatigue, evidenced by a steady 20% decline in CTR over the last 7 days.\",\n",
      "        \"driver\": \"Audience Fatigue / Creative Saturation\",\n",
      "        \"metrics_to_validate\": [\n",
      "            \"daily_ctr\",\n",
      "            \"impressions\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"hypothesis_id\": \"H2\",\n",
      "        \"hypothesis\": \"Spend spiked by 30% on the last two days with no corresponding revenue spike, suggesting a major Bid/Budget Inefficiency.\",\n",
      "        \"driver\": \"Budget/Bid Inefficiency\",\n",
      "        \"metrics_to_validate\": [\n",
      "            \"spend\",\n",
      "            \"revenue\",\n",
      "            \"daily_roas\"\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def generate_insights(data_summary: dict, user_query: str) -> list:\n",
    "    \"\"\"Simulates the Insight Agent using the structured prompt template.\"\"\"\n",
    "    \n",
    "    prompt_template = INSIGHT_PROMPT_CONTENT\n",
    "    \n",
    "    performance_str = \"\\n\".join([\n",
    "        f\"Date: {d['date']}, ROAS: {d['daily_roas']:.2f}, CTR: {d['daily_ctr']:.2f}%, Spend: {d['spend']:.0f}\"\n",
    "        for d in data_summary['Daily_Performance']\n",
    "    ])\n",
    "\n",
    "    final_prompt = prompt_template.format(\n",
    "        USER_QUERY=user_query,\n",
    "        TIMEFRAME_START=data_summary['Timeframe_Start'],\n",
    "        TIMEFRAME_END=data_summary['Timeframe_End'],\n",
    "        DAILY_PERFORMANCE_DATA=performance_str\n",
    "    )\n",
    "\n",
    "    dummy_insights = [\n",
    "        {\n",
    "            \"hypothesis_id\": \"H1\",\n",
    "            \"hypothesis\": \"The ROAS dropped primarily due to Audience Fatigue, evidenced by a steady 20% decline in CTR over the last 7 days.\",\n",
    "            \"driver\": \"Audience Fatigue / Creative Saturation\",\n",
    "            \"metrics_to_validate\": [\"daily_ctr\", \"impressions\"]\n",
    "        },\n",
    "        {\n",
    "            \"hypothesis_id\": \"H2\",\n",
    "            \"hypothesis\": \"Spend spiked by 30% on the last two days with no corresponding revenue spike, suggesting a major Bid/Budget Inefficiency.\",\n",
    "            \"driver\": \"Budget/Bid Inefficiency\",\n",
    "            \"metrics_to_validate\": [\"spend\", \"revenue\", \"daily_roas\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return dummy_insights\n",
    "\n",
    "\n",
    "user_query = \"Analyze why ROAS dropped by 15% this past week.\"\n",
    "insights_list = generate_insights(data_agent_summary, user_query)\n",
    "\n",
    "print(\"\\n--- Insight Agent Generated Hypotheses (Input for Evaluator) ---\")\n",
    "print(json.dumps(insights_list, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca88f747-f820-4c1b-8e1d-8fb890be9d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluator Agent Output (Validated Hypotheses) ---\n",
      "[\n",
      "    {\n",
      "        \"hypothesis_id\": \"H1\",\n",
      "        \"hypothesis\": \"The ROAS dropped primarily due to Audience Fatigue, evidenced by a steady 20% decline in CTR over the last 7 days.\",\n",
      "        \"driver\": \"Audience Fatigue / Creative Saturation\",\n",
      "        \"validation_status\": \"PARTIALLY_CONFIRMED\",\n",
      "        \"confidence_score\": 0.7,\n",
      "        \"quantitative_evidence\": \"Daily CTR declined slightly by 8.6%. This contributes to the drop but is not the sole factor.\"\n",
      "    },\n",
      "    {\n",
      "        \"hypothesis_id\": \"H2\",\n",
      "        \"hypothesis\": \"Spend spiked by 30% on the last two days with no corresponding revenue spike, suggesting a major Bid/Budget Inefficiency.\",\n",
      "        \"driver\": \"Budget/Bid Inefficiency\",\n",
      "        \"validation_status\": \"REJECTED\",\n",
      "        \"confidence_score\": 0.45,\n",
      "        \"quantitative_evidence\": \"No significant recent spike in spend was observed, ruling out this driver.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_insights(insights_list: list, daily_df: pd.DataFrame) -> list:\n",
    "    \"\"\"Validates hypotheses quantitatively and assigns a confidence score.\"\"\"\n",
    "    validated_insights = []\n",
    "    \n",
    "    start_date_ctr = daily_df['daily_ctr'].iloc[0]\n",
    "    end_date_ctr = daily_df['daily_ctr'].iloc[-1]\n",
    "    \n",
    "    for insight in insights_list:\n",
    "        \n",
    "        confidence = 0.0\n",
    "        status = \"UNTESTED\"\n",
    "        evidence = \"Quantitative check logic not implemented for this hypothesis type.\"\n",
    "\n",
    "        if insight['hypothesis_id'] == 'H1':\n",
    "            ctr_decline = start_date_ctr - end_date_ctr\n",
    "            ctr_drop_percent = ctr_decline / start_date_ctr if start_date_ctr != 0 else 0\n",
    "            \n",
    "            if ctr_drop_percent > 0.15: \n",
    "                confidence = 0.90\n",
    "                status = \"CONFIRMED\"\n",
    "                evidence = f\"Daily CTR dropped significantly from {start_date_ctr:.2f}% to {end_date_ctr:.2f}%, a {ctr_drop_percent*100:.1f}% decline. This confirms creative saturation.\"\n",
    "            elif ctr_drop_percent > 0.05: \n",
    "                confidence = 0.70\n",
    "                status = \"PARTIALLY_CONFIRMED\"\n",
    "                evidence = f\"Daily CTR declined slightly by {ctr_drop_percent*100:.1f}%. This contributes to the drop but is not the sole factor.\"\n",
    "            else:\n",
    "                confidence = 0.30\n",
    "                status = \"WEAK_EVIDENCE\"\n",
    "                evidence = \"CTR decline was minimal; hypothesis is weakly supported.\"\n",
    "\n",
    "        elif insight['hypothesis_id'] == 'H2':\n",
    "            avg_spend_prior = daily_df['spend'].iloc[:-2].mean()\n",
    "            avg_spend_last_2d = daily_df['spend'].iloc[-2:].mean()\n",
    "            spend_increase_ratio = avg_spend_last_2d / avg_spend_prior if avg_spend_prior != 0 else 0\n",
    "            \n",
    "            if spend_increase_ratio > 1.30: \n",
    "                confidence = 0.85\n",
    "                status = \"CONFIRMED\"\n",
    "                evidence = f\"Average daily spend jumped from ${avg_spend_prior:.0f} to ${avg_spend_last_2d:.0f} in the last two days, an increase of {spend_increase_ratio*100:.0f}%. This spending spike aligns with the ROAS drop.\"\n",
    "            else:\n",
    "                confidence = 0.45\n",
    "                status = \"REJECTED\"\n",
    "                evidence = \"No significant recent spike in spend was observed, ruling out this driver.\"\n",
    "        \n",
    "        validated_insights.append({\n",
    "            \"hypothesis_id\": insight['hypothesis_id'],\n",
    "            \"hypothesis\": insight['hypothesis'],\n",
    "            \"driver\": insight['driver'],\n",
    "            \"validation_status\": status,\n",
    "            \"confidence_score\": confidence,\n",
    "            \"quantitative_evidence\": evidence\n",
    "        })\n",
    "        \n",
    "    return validated_insights\n",
    "\n",
    "final_insights = evaluate_insights(insights_list, daily_df)\n",
    "print(\"\\n--- Evaluator Agent Output (Validated Hypotheses) ---\")\n",
    "print(json.dumps(final_insights, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d1e974-faa5-450b-8640-a4e6d53e5a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validated Insights (Confidence >= 0.6): 1\n",
      "Insights Needing Retry: 1\n",
      "\n",
      "✅ Validated Insights Saved to reports\\insights.json\n"
     ]
    }
   ],
   "source": [
    "CONFIDENCE_MIN = 0.6  \n",
    "\n",
    "validated_final = []\n",
    "needs_retry = []\n",
    "\n",
    "for insight in final_insights:\n",
    "    if insight['confidence_score'] >= CONFIDENCE_MIN:\n",
    "        validated_final.append(insight)\n",
    "    else:\n",
    "        feedback = f\"Hypothesis '{insight['hypothesis']}' had low confidence ({insight['confidence_score']:.2f}) because the evidence was: {insight['quantitative_evidence']}. Please refine the analysis.\"\n",
    "        needs_retry.append({\"id\": insight['hypothesis_id'], \"feedback\": feedback})\n",
    "\n",
    "print(f\"\\nValidated Insights (Confidence >= {CONFIDENCE_MIN}): {len(validated_final)}\")\n",
    "print(f\"Insights Needing Retry: {len(needs_retry)}\")\n",
    "\n",
    "output_dir = 'reports' \n",
    "output_path_insights = Path(output_dir) / 'insights.json' \n",
    "\n",
    "Path(output_dir).mkdir(exist_ok=True) \n",
    "\n",
    "with open(output_path_insights, 'w') as f:\n",
    "    json.dump(validated_final, f, indent=4)\n",
    "\n",
    "print(f\"\\n✅ Validated Insights Saved to {output_path_insights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81630e50-cf18-4c5e-adbc-34aa6b66191c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d76c28-584b-4749-812f-fdc4ec3c04fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
